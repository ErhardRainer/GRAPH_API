{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "| Version | Datum       | Bearbeiter | Anmerkung          |\n",
                "|---------|-------------|------------|--------------------|\n",
                "| 1.0     | 27.02.2025  | Erhard Rainer  | Erste Version      |\n",
                "| 1.1     | 28.08.2025  | Erhard Rainer | Übertragung in Jupiter Notebook |\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "6e34df8b-f0ff-4262-9567-d7f391a396df"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# SharePoint 2 SQL (klassische Benutzername und Passwort Anmeldung)\n",
                "\n",
                "## Was macht das Skript?\n",
                "\n",
                "Es liest eine Konfigurationstabelle aus SQL, holt auf Basis dieser Konfiguration Einträge aus **SharePoint-Listen**, transformiert die Spalten gemäß Mapping und schreibt die Daten in **SQL-Tabellen** (optional mit vorherigem `TRUNCATE` und optionalem SP-Nachlauf). Für jeden Konfigurationseintrag läuft derselbe ETL-Zyklus.\n",
                "\n",
                "## Ablauf (High Level)\n",
                "\n",
                "1. **Config laden** (`config.json`): Nutzer/Passwort für SharePoint sowie SQL (Server, User, Passwort).\n",
                "    \n",
                "2. **Konfiguration aus SQL lesen**: `SELECT * FROM [config].[Sharepoint] WHERE Disabled = 0` (DB standardmäßig `BI_RAW`).\n",
                "    \n",
                "3. **Pro Konfigurationseintrag:**\n",
                "    \n",
                "    - Parameter holen: `SITE_URL`, `LIST_TITLE`, Ziel-DB/Schema/Tabelle, Spalten-Mapping (`Source_columns` → `Translated_columns`), optional `SP`.\n",
                "        \n",
                "    - **SharePoint lesen**:\n",
                "        \n",
                "        - Login mit Benutzername/Passwort.\n",
                "            \n",
                "        - Liste per Paging in **Batches à 500** Items abrufen.\n",
                "            \n",
                "        - Spalten laut Mapping umbenennen; fehlende Spalten werden einmalig pro Name gewarnt.\n",
                "            \n",
                "        - `Anzeigeseite` (DispForm-URL) aus `site_url`, `list_title`, `ID` erzeugen.\n",
                "            \n",
                "    - **SQL-Ziel initialisieren** (SQLAlchemy/ODBC):\n",
                "        \n",
                "        - Tabelle bei Bedarf **anlegen** (Datentypen aus `pandas`\\-DTypes abgeleitet).\n",
                "            \n",
                "        - Optional **leeren** (`TRUNCATE`) und dann per `to_sql` **anhängen**.\n",
                "            \n",
                "        - Optional **Stored Procedure** ausführen (`EXEC <SP>`).\n",
                "            \n",
                "4. **Logging auf Konsole**, dann nächster Eintrag / Ende.\n",
                "    \n",
                "\n",
                "## Welche Authentifizierung verwendet es?\n",
                "\n",
                "- **SharePoint Online**:\n",
                "    \n",
                "    - `office365-sharepoint` mit `UserCredential(username, password)` → **klassische Benutzername/Passwort-Anmeldung** (delegierte Benutzeridentität; kein App-Registrat, kein MSAL/OAuth-Client-Credentials).\n",
                "        \n",
                "    - Hinweis: Das ist praktisch, aber sicherheitlich/operativ schwächer; Microsoft empfiehlt heute App-Only (Zertifikat/Secret) über **Microsoft Graph**.\n",
                "        \n",
                "- **SQL Server**:\n",
                "    \n",
                "    - **SQL-Authentifizierung** (User/Pass) in der ODBC-Connection (`mssql+pyodbc`, **ODBC Driver 17**).\n",
                "        \n",
                "\n",
                "## Erwartete Spalten in `[config].[Sharepoint]`\n",
                "\n",
                "Mindestens:  \n",
                "`SITE_URL`, `LIST_TITLE`, `DB_NAME`, `DB_SCHEMA`, `DB_TABLE`, `Source_columns`, `Translated_columns`, `Disabled` (0/1), optional `SP`.\n",
                "\n",
                "## Besonderheiten / Edge Cases\n",
                "\n",
                "- Falls die Liste **leer** ist → leeres DataFrame, kein Insert.\n",
                "    \n",
                "- Wenn `Source_columns` ≠ `Translated_columns` in der Länge → **Fehler**.\n",
                "    \n",
                "- Wenn keine `ID` in den Daten → Abbruch (für die DispForm-URL nötig).\n",
                "    \n",
                "- Datentypen werden heuristisch aus `pandas`\\-DTypes abgeleitet (z. B. `int64` → `INTEGER`, `datetime` → `DateTime`, sonst `String`).\n",
                "    \n",
                "\n",
                "## Kurzer Sicherheitshinweis (empfohlen)\n",
                "\n",
                "- Secrets nicht im Klartext: z. B. **Azure Key Vault**, Umgebungsvariablen, `.env`.\n",
                "    \n",
                "- Für SharePoint: möglichst auf **App-Only über MSAL/Graph** (Client-ID/Secret oder Zertifikat) umstellen; Least Privilege.\n",
                "    \n",
                "- ODBC **Driver 18** mit `Encrypt=yes;TrustServerCertificate=no` erwägen."
            ],
            "metadata": {
                "azdata_cell_guid": "0e6b3bc2-f696-4e15-9a1b-74021a274240"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "%pip install --upgrade pandas sqlalchemy pyodbc Office365-REST-Python-Client\r\n",
                "%pip install --upgrade python-dotenv tqdm pyarrow"
            ],
            "metadata": {
                "azdata_cell_guid": "09e51674-db81-443d-820b-fde781b9a6d0",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Test der Module"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "93d9ff9d-ff9a-49ca-bdc4-a9d4c35130d2"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas, sqlalchemy, pyodbc\r\n",
                "import office365\r\n",
                "print(\"pandas:\", pandas.__version__)\r\n",
                "print(\"sqlalchemy:\", sqlalchemy.__version__)\r\n",
                "print(\"pyodbc:\", pyodbc.version)\r\n",
                "print(\"ODBC-Treiber:\", pyodbc.drivers())\r\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "b7ef452a-302b-4003-bcb5-6df9897b17c2"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "pandas: 2.0.3\nsqlalchemy: 2.0.43\npyodbc: 5.2.0\nODBC-Treiber: ['SQL Server', 'ODBC Driver 17 for SQL Server', 'ODBC Driver 18 for SQL Server', 'Microsoft Access Driver (*.mdb, *.accdb)', 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)', 'Microsoft Access Text Driver (*.txt, *.csv)', 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)']\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Systemvoraussetzung (nicht per pip)\n",
                "\n",
                "- **Microsoft ODBC Driver 17/18 for SQL Server** muss am System installiert sein.  \n",
                "    Falls du **18** nutzt, passe im Connection-String den Treiber an:\n",
                "    \n",
                "    - `...driver=ODBC+Driver+18+for+SQL+Server bzw.` `ODBC+Driver+17+for+SQL+Server`."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "bee4d4b7-f434-4901-a0d1-fa6438212b8a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Aufbau der Config-Datei\n",
                "\n",
                "Es gibt auch Prüfskripte, um den Aufbau der Config-Datei zur prüfen siehe [hier](config_json.ipynb)."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "c712e7c9-d0de-461c-9619-30cde79ca422"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "{\r\n",
                "  \"sql\": {\r\n",
                "    \"username\": \"DEIN_SQL_USER\",\r\n",
                "    \"password\": \"DEIN_SQL_PASS\",\r\n",
                "    \"server\": \"Server\",\r\n",
                "    \"DB\": \"DB\",\r\n",
                "  },\r\n",
                "  \"sharepoint\": {\r\n",
                "    \"username\": \"user@tenant.onmicrosoft.com\",\r\n",
                "    \"password\": \"DEIN_SP_PASS\"\r\n",
                "  }\r\n",
                "}"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "541f4c41-54c7-4b8b-81d7-89c7005e2f6f"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "# das Skript"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "6fc1e3ac-62de-4b92-951c-91a6e62c1ecf"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import json\r\n",
                "import os\r\n",
                "import pandas as pd\r\n",
                "import urllib.parse\r\n",
                "from sqlalchemy import create_engine, MetaData, Table, Column, text\r\n",
                "from sqlalchemy.types import String, Integer, Float, DateTime, Boolean\r\n",
                "from office365.sharepoint.client_context import ClientContext\r\n",
                "from office365.runtime.auth.user_credential import UserCredential\r\n",
                "\r\n",
                "# --------------------------------------------------------------------------------\r\n",
                "# Konfiguration aus config.json laden (mit UTF-8-Encoding) über einen absoluten Pfad\r\n",
                "# --------------------------------------------------------------------------------\r\n",
                "# Absoluter Pfad zur config.json (anpassen, falls nötig)\r\n",
                "config_path = r\"C:\\python\\Scripts\\config.json\"  \r\n",
                "with open(config_path, \"r\", encoding=\"utf-8\") as f:\r\n",
                "    config = json.load(f)\r\n",
                "\r\n",
                "SHAREPOINT_USERNAME = config[\"sharepoint\"][\"username\"]\r\n",
                "SHAREPOINT_PASSWORD = config[\"sharepoint\"][\"password\"]\r\n",
                "\r\n",
                "SQL_USERNAME = config[\"sql\"][\"username\"]\r\n",
                "SQL_PASSWORD = config[\"sql\"][\"password\"]\r\n",
                "SQL_SERVER = config[\"sql\"][\"server\"]\r\n",
                "\r\n",
                "# Funktion zur URL-Kodierung der SQL-Zugangsdaten\r\n",
                "def encode_sql_credentials(username, password):\r\n",
                "    username_enc = urllib.parse.quote_plus(username)\r\n",
                "    password_enc = urllib.parse.quote_plus(password)\r\n",
                "    return username_enc, password_enc\r\n",
                "\r\n",
                "# --------------------------------------------------------------------------------\r\n",
                "# Hilfsfunktionen\r\n",
                "# --------------------------------------------------------------------------------\r\n",
                "\r\n",
                "def read_sharepoint_config(db_name=\"BI_RAW\"):\r\n",
                "    \"\"\"\r\n",
                "    Liest die Konfiguration aus der Tabelle [config].[Sharepoint] in der angegebenen\r\n",
                "    Datenbank (Standard: BI_RAW) und liefert nur die Einträge zurück, bei denen Disabled=0.\r\n",
                "    \"\"\"\r\n",
                "    username_enc, password_enc = encode_sql_credentials(SQL_USERNAME, SQL_PASSWORD)\r\n",
                "    engine = create_engine(\r\n",
                "        f\"mssql+pyodbc://{username_enc}:{password_enc}@{SQL_SERVER}/{db_name}?driver=ODBC+Driver+17+for+SQL+Server\"\r\n",
                "    )\r\n",
                "    query = \"SELECT * FROM [config].[Sharepoint] WHERE Disabled = 0\"\r\n",
                "    df_config = pd.read_sql(query, engine)\r\n",
                "    return df_config\r\n",
                "\r\n",
                "def get_sharepoint_list_items(site_url, list_title, username, password, source_columns, translated_columns):\r\n",
                "    \"\"\"\r\n",
                "    Authentifiziert sich bei SharePoint Online und ruft Elemente aus der angegebenen Liste ab.\r\n",
                "    Dabei werden die Einträge in Batches von 500 Elementen abgerufen.\r\n",
                "    Die definierten Spalten (source_columns) werden in die übersetzten Spalten (translated_columns)\r\n",
                "    überführt und es wird ein DispForm-Link hinzugefügt.\r\n",
                "    \r\n",
                "    Falls eine erwartete Spalte nicht gefunden wird, wird eine Warnung ausgegeben, die\r\n",
                "    alle in dem jeweiligen Listeneintrag verfügbaren Spalten anzeigt.\r\n",
                "    \"\"\"\r\n",
                "    try:\r\n",
                "        # Authentifizierung und Zugriff auf die Liste\r\n",
                "        ctx = ClientContext(site_url).with_credentials(UserCredential(username, password))\r\n",
                "        s_list = ctx.web.lists.get_by_title(list_title)\r\n",
                "        \r\n",
                "        # Alle Listeneinträge in Batches von 500 abrufen\r\n",
                "        batch_size = 500\r\n",
                "        paged_items = s_list.items.paged(batch_size)\r\n",
                "        ctx.load(paged_items)\r\n",
                "        ctx.execute_query()\r\n",
                "        \r\n",
                "        all_items = list(paged_items)\r\n",
                "        while paged_items.has_next:\r\n",
                "            paged_items = paged_items.get_next()\r\n",
                "            ctx.load(paged_items)\r\n",
                "            ctx.execute_query()\r\n",
                "            all_items.extend(list(paged_items))\r\n",
                "        \r\n",
                "        print(f\"Gesamtanzahl der Listeneinträge: {len(all_items)}\")\r\n",
                "        \r\n",
                "        # Falls die Liste leer ist, direkt ein leeres DataFrame zurückgeben\r\n",
                "        if len(all_items) == 0:\r\n",
                "            print(\"Die SharePoint-Liste ist leer. Es werden keine Daten verarbeitet.\")\r\n",
                "            return pd.DataFrame()\r\n",
                "        \r\n",
                "        # Überprüfen, ob beide Spaltenlisten gleich lang sind\r\n",
                "        if len(source_columns) != len(translated_columns):\r\n",
                "            raise ValueError(\"Die Listen 'source_columns' und 'translated_columns' müssen die gleiche Länge haben.\")\r\n",
                "        \r\n",
                "        # Mapping-Dictionary für die Spaltenübersetzung erstellen\r\n",
                "        column_mapping = dict(zip(source_columns, translated_columns))\r\n",
                "        \r\n",
                "        # Vermerke, welche fehlende Spalte bereits gemeldet wurde (um Dopplungen zu vermeiden)\r\n",
                "        missing_reported = {}\r\n",
                "        \r\n",
                "        # Übersetzen der Listenelemente\r\n",
                "        translated_data = []\r\n",
                "        for item in all_items:\r\n",
                "            translated_item = {}\r\n",
                "            for src_col, trans_col in column_mapping.items():\r\n",
                "                if src_col in item.properties:\r\n",
                "                    translated_item[trans_col] = item.properties.get(src_col, None)\r\n",
                "                else:\r\n",
                "                    if src_col not in missing_reported:\r\n",
                "                        available = list(item.properties.keys())\r\n",
                "                        print(f\"Warnung: Spalte '{src_col}' nicht gefunden. Verfügbare Spalten: {available}\")\r\n",
                "                        missing_reported[src_col] = True\r\n",
                "                    translated_item[trans_col] = None\r\n",
                "            translated_data.append(translated_item)\r\n",
                "        \r\n",
                "        # DataFrame erstellen\r\n",
                "        df = pd.DataFrame(translated_data)\r\n",
                "        \r\n",
                "        if 'ID' not in df.columns:\r\n",
                "            print(\"Keine 'ID'-Spalte im DataFrame gefunden. Abbruch.\")\r\n",
                "            return None\r\n",
                "        \r\n",
                "        # DispForm-Links generieren und als neue Spalte hinzufügen\r\n",
                "        df['Anzeigeseite'] = df['ID'].apply(lambda id: generate_dispform_url(site_url, list_title, id))\r\n",
                "        \r\n",
                "        return df\r\n",
                "    except Exception as e:\r\n",
                "        print(f\"Ein Fehler ist aufgetreten (Liste '{list_title}'): {e}\")\r\n",
                "        return None\r\n",
                "\r\n",
                "def generate_dispform_url(site_url, list_title, item_id):\r\n",
                "    \"\"\"\r\n",
                "    Generiert die URL zur DispForm-Seite eines SharePoint-Listeneintrags.\r\n",
                "    \"\"\"\r\n",
                "    encoded_list_title = urllib.parse.quote(list_title)\r\n",
                "    dispform_url = f\"{site_url}/Lists/{encoded_list_title}/DispForm.aspx?ID={item_id}\"\r\n",
                "    return dispform_url\r\n",
                "\r\n",
                "def initialize_engine(db_username, db_password, db_server, db_name, db_schema):\r\n",
                "    \"\"\"\r\n",
                "    Initialisiert die SQLAlchemy-Engine für die Verbindung zur Datenbank.\r\n",
                "    \"\"\"\r\n",
                "    username_enc, password_enc = encode_sql_credentials(db_username, db_password)\r\n",
                "    engine = create_engine(\r\n",
                "        f'mssql+pyodbc://{username_enc}:{password_enc}@{db_server}/{db_name}?driver=ODBC+Driver+17+for+SQL+Server'\r\n",
                "    )\r\n",
                "    return engine, db_schema\r\n",
                "\r\n",
                "def create_table_if_not_exists(engine, table_name, df, schema):\r\n",
                "    \"\"\"\r\n",
                "    Erstellt die Tabelle, wenn sie nicht existiert, basierend auf dem DataFrame.\r\n",
                "    \"\"\"\r\n",
                "    metadata = MetaData(schema=schema)\r\n",
                "    columns = []\r\n",
                "    for column_name, dtype in zip(df.columns, df.dtypes):\r\n",
                "        if dtype == \"int64\":\r\n",
                "            columns.append(Column(column_name, Integer))\r\n",
                "        elif dtype == \"float64\":\r\n",
                "            columns.append(Column(column_name, Float))\r\n",
                "        elif dtype == \"bool\":\r\n",
                "            columns.append(Column(column_name, Boolean))\r\n",
                "        elif str(dtype).startswith(\"datetime\"):\r\n",
                "            columns.append(Column(column_name, DateTime))\r\n",
                "        else:\r\n",
                "            columns.append(Column(column_name, String))\r\n",
                "    table = Table(table_name, metadata, *columns, extend_existing=True)\r\n",
                "    metadata.create_all(engine)\r\n",
                "\r\n",
                "def insertSQL(engine, table_name, truncate, df, schema, sp_name=None):\r\n",
                "    \"\"\"\r\n",
                "    Fügt Daten aus einem DataFrame in eine SQL-Tabelle ein. Optional wird die Tabelle vorher geleert.\r\n",
                "    Falls die Tabelle nicht existiert, wird sie automatisch erstellt.\r\n",
                "    Nach dem Einfügen kann optional eine Stored Procedure ausgeführt werden.\r\n",
                "    \"\"\"\r\n",
                "    try:\r\n",
                "        create_table_if_not_exists(engine, table_name, df, schema)\r\n",
                "        \r\n",
                "        if truncate == 1:\r\n",
                "            with engine.begin() as conn:\r\n",
                "                conn.execute(text(f\"TRUNCATE TABLE {schema}.{table_name}\"))\r\n",
                "                print(f\"Tabelle {schema}.{table_name} wurde geleert.\")\r\n",
                "        \r\n",
                "        if df is None or df.empty:\r\n",
                "            print(\"Keine gültigen Daten zum Einfügen vorhanden.\")\r\n",
                "            return\r\n",
                "        \r\n",
                "        df.to_sql(table_name, engine, schema=schema, if_exists='append', index=False)\r\n",
                "        print(f\"Daten erfolgreich in die Tabelle {schema}.{table_name} eingefügt.\")\r\n",
                "        \r\n",
                "        if sp_name:\r\n",
                "            with engine.connect() as conn:\r\n",
                "                print(f\"Führe Stored Procedure '{sp_name}' aus...\")\r\n",
                "                conn.execute(text(f\"EXEC {sp_name}\"))\r\n",
                "                print(f\"Stored Procedure '{sp_name}' erfolgreich ausgeführt.\")\r\n",
                "    \r\n",
                "    except Exception as e:\r\n",
                "        print(f\"Ein Fehler ist beim Einfügen in die Tabelle {schema}.{table_name} aufgetreten: {e}\")\r\n",
                "\r\n",
                "# --------------------------------------------------------------------------------\r\n",
                "# Main-Prozess\r\n",
                "# --------------------------------------------------------------------------------\r\n",
                "\r\n",
                "if __name__ == \"__main__\":\r\n",
                "    # 1) Config (in BI_RAW / [config].[Sharepoint]) auslesen\r\n",
                "    df_config = read_sharepoint_config(db_name=\"BI_RAW\")\r\n",
                "    \r\n",
                "    if df_config.empty:\r\n",
                "        print(\"Keine aktiven (Disabled=0) Einträge in [config].[Sharepoint] gefunden.\")\r\n",
                "        exit()\r\n",
                "\r\n",
                "    # 2) Über jeden aktiven Eintrag iterieren\r\n",
                "    for idx, row in df_config.iterrows():\r\n",
                "        site_url = row[\"SITE_URL\"]\r\n",
                "        list_title = row[\"LIST_TITLE\"]\r\n",
                "        \r\n",
                "        db_name = row[\"DB_NAME\"]\r\n",
                "        db_schema = row[\"DB_SCHEMA\"]\r\n",
                "        db_table = row[\"DB_TABLE\"]\r\n",
                "        \r\n",
                "        source_columns = [col.strip() for col in row[\"Source_columns\"].split(\",\")]\r\n",
                "        translated_columns = [col.strip() for col in row[\"Translated_columns\"].split(\",\")]\r\n",
                "        \r\n",
                "        sp_name = row[\"SP\"] if \"SP\" in row and pd.notnull(row[\"SP\"]) else None\r\n",
                "\r\n",
                "        print(f\"\\nVerarbeite Eintrag aus [config].[Sharepoint]:\")\r\n",
                "        print(f\" - site_url: {site_url}\")\r\n",
                "        print(f\" - list_title: {list_title}\")\r\n",
                "        print(f\" - db_table: {db_schema}.{db_table}\")\r\n",
                "        print(f\" - Stored Procedure: {sp_name if sp_name else 'Keine'}\")\r\n",
                "        print(f\" - source_columns: {source_columns}\")\r\n",
                "        print(f\" - translated_columns: {translated_columns}\")\r\n",
                "        \r\n",
                "        # 3) Daten aus SharePoint holen\r\n",
                "        df_sharepoint = get_sharepoint_list_items(\r\n",
                "            site_url=site_url,\r\n",
                "            list_title=list_title,\r\n",
                "            username=SHAREPOINT_USERNAME,\r\n",
                "            password=SHAREPOINT_PASSWORD,\r\n",
                "            source_columns=source_columns,\r\n",
                "            translated_columns=translated_columns\r\n",
                "        )\r\n",
                "\r\n",
                "        if df_sharepoint is None or df_sharepoint.empty:\r\n",
                "            print(\"Die SharePoint-Liste ist leer oder es wurden keine Daten abgerufen.\")\r\n",
                "            continue\r\n",
                "        \r\n",
                "        print(f\"Anzahl der abgerufenen Elemente: {len(df_sharepoint)}\")\r\n",
                "        \r\n",
                "        # 4) Engine initialisieren für das Ziel-DB (db_name aus Config)\r\n",
                "        engine, schema = initialize_engine(\r\n",
                "            db_username=SQL_USERNAME,\r\n",
                "            db_password=SQL_PASSWORD,\r\n",
                "            db_server=SQL_SERVER,\r\n",
                "            db_name=db_name,\r\n",
                "            db_schema=db_schema\r\n",
                "        )\r\n",
                "        \r\n",
                "        # 5) Daten einfügen (truncate=1 => Tabelle vorher leeren, falls gewünscht)\r\n",
                "        insertSQL(engine, db_table, 1, df_sharepoint, schema, sp_name=sp_name)\r\n",
                "    \r\n",
                "    print(\"\\nVerarbeitung beendet.\")"
            ],
            "metadata": {
                "azdata_cell_guid": "bc9c615b-5443-4fec-a872-bdbc5e93f809",
                "language": "python"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Fehlerhandling\n",
                "\n",
                "Die Fehlermeldung „Ein Fehler ist aufgetreten (Liste ‘XY’): An error occurred while retrieving auth cookies from …/\\_forms/default.aspx?wa=wsignin1.0“ deutet darauf hin, dass dein Code (über `UserCredential`/CSOM bzw. Office365-REST-Python-Client) versucht, alte **WS-Federation/Forms-Auth**\\-Cookies (`FedAuth`/`rtFa`) per **wsignin1.0** zu beziehen – also eine **Legacy-Anmeldung mit Benutzername/Passwort** gegen SharePoint Online. Genau diese Methode gilt heute **nicht mehr als State of the Art** und ist in vielen Tenants durch **Conditional-Access-Policies**, **MFA-Pflicht**, „Block Legacy Authentication“ oder generell deaktivierte WS-Trust/WS-Fed-Flows unterbunden. Ergebnis: Der Cookie-Abruf wird abgewiesen oder in einen interaktiven Flow umgeleitet, den ein Headless-Script nicht durchlaufen kann. Kurz: Solange du `UserCredential(username, password)` nutzt, kollidierst du mit modernen Sicherheitsvorgaben. Der robuste Weg ist **moderne OAuth2/AAD-Authentifizierung**: registriere eine **App** in Entra ID (Azure AD), nutze **App-Only (Client-Credentials)** idealerweise mit **Zertifikat** (statt Secret), erteile **least-privilege**\\-Rechte (für Microsoft Graph z. B. **`Sites.Selected`** und die Site explizit freischalten; alternativ SharePoint App-Permissions), hole dir das Token mit **MSAL** und rufe die Daten anschließend über **Graph** (`/sites/{id}/lists/{title}/items?expand=fields`) oder über die **SharePoint REST/CSOM** mit **Bearer-Token** ab (auch der Office365-Client unterstützt `ClientCredential`). Achte darauf, dass keine interaktiven Faktoren (MFA) im Server-Kontext verlangt werden, Secrets/Zertifikate sicher gelagert sind (Key Vault/Secrets Manager), und dass deine Policies (CA, Legacy-Auth-Block) zum App-Only-Szenario passen. In Summe erklärt der Fehler also nicht „falsche Credentials“, sondern dass **passwortbasierte Cookie-Flows** im Tenant **blockiert** sind – eine gewollte Sicherheitsmaßnahme –, und die Lösung ist die **Umstellung auf moderne, nicht-interaktive App-Only-Authentifizierung** mit Token-basiertem Zugriff."
            ],
            "metadata": {
                "azdata_cell_guid": "5a02e390-1195-4ae6-87b4-0f8f97bbdadf"
            },
            "attachments": {}
        }
    ]

}


